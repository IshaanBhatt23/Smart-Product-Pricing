# Smart Product Pricing Prediction ğŸš€

This repository contains the code for a machine learning solution to the **Smart Product Pricing Challenge**, which achieved a **rank of 629 out of 23,000 (Top 2.73%)**.

The goal of this project is to **predict the price of e-commerce products** using a **multimodal approach**, leveraging both **textual descriptions** and **product images**. This implementation combines advanced text-based feature engineering with deep-learning image embeddings to build a **high-performance ensemble model**.

---

## ğŸ”¥ Features

### ğŸ“ Text-Based Features

This solution engineers a rich set of text-based attributes:

* **TF-IDF Representation**
  Unigram and bigram TF-IDF for core text analysis.

* **Item Pack Quantity (IPQ) Extraction**
  Extracts quantity values (e.g., *Pack of 12*, *6 Count*) using regex.

* **Keyword Detection**
  Binary indicators for value-defining keywords:

  * *Quality*: premium, organic, heavy-duty
  * *Bundling*: set, bundle, kit
  * *Condition*: refurbished, new, generic

* **Text Metadata**

  * Character count
  * Word count
  * Uppercase ratio

---

### ğŸ–¼ï¸ Image-Based Features

* **EfficientNetB0 Embeddings**
  A pre-trained EfficientNetB0 model is used to extract dense numerical vectors from product images.

* **High-Dimensional Feature Extraction**
  Captures visual quality, complexity, material, and product structure.

---

## âš™ï¸ Methodology

### 1. **Data Pre-processing**

* Clean and engineer all text features (IPQ, Keywords, Metadata, TF-IDF).
* Process product images using EfficientNetB0 to generate embeddings.

### 2. **Feature Fusion**

Combine:

* Sparse + numerical text features
* Dense image embeddings
  â†’ into a single multimodal feature matrix.

### 3. **Model Training**

Uses a two-model **ensemble**:

* **LightGBM (LGBMRegressor)**
* **HistGradientBoostingRegressor**

Target is transformed using:
`log(1 + price)`

### 4. **Persistence**

Trained models and preprocessed datasets are saved as `.pkl` files.

### 5. **Prediction**

Load saved files â†’ run predictions â†’ ensemble â†’ convert back to original price scale.

---

## ğŸš€ Getting Started

### **Prerequisites**

* Python 3.7+
* Git

---

## ğŸ“¥ Installation & Setup

### 1. Clone the repository

```bash
git clone https://github.com/your-username/amazon-price-prediction.git
cd amazon-price-prediction
```

### 2. Create and activate a virtual environment

```bash
# Create
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Linux/macOS)
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ§ª Usage

### Step 1 â€” Place Your Data

Create a folder named **Dataset** in the root:

```
Dataset/
 â”œâ”€â”€ train.csv
 â””â”€â”€ test.csv
```

Add image folders inside it if required.

---

### Step 2 â€” Train the Model (run once)

```bash
python train_and_save_model.py
```

This will generate:

* `lightgbm_model.pkl`
* `histgb_model.pkl`
* `X_test_processed.pkl`
* etc.

---

### Step 3 â€” Generate Predictions

```bash
python load_and_predict.py
```

This will create:

```
submission.csv
```

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ Dataset/
â”‚   â”œâ”€â”€ train.csv
â”‚   â””â”€â”€ test.csv
â”œâ”€â”€ .gitignore
â”œâ”€â”€ train_and_save_model.py     # Pre-processing + training
â”œâ”€â”€ load_and_predict.py         # Load models + prediction
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md
```

---

## ğŸ¯ Advanced Techniques

### ğŸ”¹ Multimodal Feature Fusion

Combining text + image features gives the model a holistic understanding of the productâ€”something neither modality could achieve alone.

### ğŸ”¹ Ensemble Modeling

Uses two strong gradient boosting models:

* LightGBM
* HistGradientBoosting

This improves robustness and accuracy.

### ğŸ”¹ Hyperparameter Tuning with Optuna

Optuna was used for extensive tuning of the LightGBM model.

A multi-hour search was conducted focusing on LGBM due to competition time constraints.

---

## ğŸ“„ License

This project is licensed under the **MIT License**.
